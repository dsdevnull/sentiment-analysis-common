{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.12/site-packages (from seaborn) (2.2.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.venv/lib/python3.12/site-packages (from seaborn) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement mathplotlib (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for mathplotlib\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.12/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from nltk) (4.66.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wordcloud in ./.venv/lib/python3.12/site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in ./.venv/lib/python3.12/site-packages (from wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.12/site-packages (from wordcloud) (10.2.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from wordcloud) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->wordcloud) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->wordcloud) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->wordcloud) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: textblob in ./.venv/lib/python3.12/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in ./.venv/lib/python3.12/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk>=3.8->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk>=3.8->textblob) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from nltk>=3.8->textblob) (4.66.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spacy in ./.venv/lib/python3.12/site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.12/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.12/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./.venv/lib/python3.12/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.12/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./.venv/lib/python3.12/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./.venv/lib/python3.12/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.12/site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.12/site-packages (from spacy) (2.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from spacy) (69.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.12/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.venv/lib/python3.12/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install seaborn\n",
    "%pip install mathplotlib\n",
    "%pip install nltk\n",
    "%pip install scikit-learn\n",
    "%pip install wordcloud\n",
    "%pip install textblob\n",
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import spacy\n",
    "import re, string, unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dsdevnull/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data = pd.read_csv(\"./data/IMDB Dataset.csv\")\n",
    "\n",
    "print(imdb_data.shape)\n",
    "imdb_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like this is a relatively simple dataset, 2 columns and 50k rows. We will need to do some data cleaning, if you notice the HTML tags present in the sample data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.describe()\n",
    "# Lots of unique values which is awesome for training a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "I decided to use regex, I saw some examples using beautiful soup, for the time being I think that is overkill and introduces dependecies that are not needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(line) -> string:\n",
    "    clean_data = re.compile(\"<.*>\")\n",
    "    return re.sub(clean_data, \"\", line)\n",
    "\n",
    "\n",
    "def remove_spec_char(line) -> string:\n",
    "    pattern = r\"[^a-zA-z0-9\\s]\"\n",
    "    return re.sub(pattern, \"\", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data[\"review\"] = imdb_data[\"review\"].apply(clean_html)\n",
    "imdb_data[\"review\"] = imdb_data[\"review\"].apply(remove_spec_char)\n",
    "imdb_data[\"review\"] = imdb_data[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the realism real...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the realism real...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically theres a family where a little boy j...  negative\n",
       "4  petter matteis love in the time of money is a ...  positive"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Stemming is something that I have not used before, it was interesting to read about it. I did some research on it and why it is important in NLP specifcally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes a while to run depending on your PC Specs\n",
    "# It took about 2m 10s on my 2018 13in MacBook Pro\n",
    "def simple_stemmer(text):\n",
    "    ps = PorterStemmer()\n",
    "    text = \" \".join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "\n",
    "imdb_data[\"review\"] = imdb_data[\"review\"].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and removing stopwords\n",
    "\n",
    "Stop words do not provide meaning to understanding the meaning of a given statement. Below you can see an exmaple of stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Creating tokenizer for later use\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words(\"english\")\n",
    "print(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  one review ha mention watch 1 oz episod youll ...  positive\n",
      "1  wonder littl product realism realli come home ...  positive\n",
      "2  thought thi wa wonder way spend time hot summe...  positive\n",
      "3  basic famili littl boy jake think zombi hi clo...  negative\n",
      "4  petter mattei love time money visual stun film...  positive\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words(line, is_lower_case=False) -> string:\n",
    "    tokens = tokenizer.tokenize(line)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [\n",
    "            token for token in tokens if token.lower() not in stopword_list\n",
    "        ]\n",
    "    filtered_text = \" \".join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "imdb_data[\"review\"] = imdb_data[\"review\"].apply(remove_stop_words)\n",
    "print(imdb_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Test/Train data for the reviews data\n",
    "norm_train_reviews = imdb_data.review[:40000]\n",
    "norm_test_reviews = imdb_data.review[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (40000, 4166498)\n",
      "BOW_cv_test: (10000, 4166498)\n"
     ]
    }
   ],
   "source": [
    "# Count vectorizer for bag of words\n",
    "cv = CountVectorizer(min_df=0.0, max_df=1.0, binary=False, ngram_range=(1, 3))\n",
    "# transformed train reviews\n",
    "cv_train_reviews = cv.fit_transform(norm_train_reviews)\n",
    "# transformed test reviews\n",
    "cv_test_reviews = cv.transform(norm_test_reviews)\n",
    "\n",
    "print(\"BOW_cv_train:\", cv_train_reviews.shape)\n",
    "print(\"BOW_cv_test:\", cv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency-Inverse Document Frequency model (TFIDF)\n",
    "\n",
    "TF-IDF is commonly used in information retrieval, text mining, and document classification tasks to identify key terms or features within documents and to rank their importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (40000, 4166498)\n",
      "Tfidf_test: (10000, 4166498)\n"
     ]
    }
   ],
   "source": [
    "tv = TfidfVectorizer(min_df=0.0, max_df=1.0, use_idf=True, ngram_range=(1, 3))\n",
    "# transformed train reviews\n",
    "tv_train_reviews = tv.fit_transform(norm_train_reviews)\n",
    "# transformed test reviews\n",
    "tv_test_reviews = tv.transform(norm_test_reviews)\n",
    "print(\"Tfidf_train:\", tv_train_reviews.shape)\n",
    "print(\"Tfidf_test:\", tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# labeling the sentient data\n",
    "lb = LabelBinarizer()\n",
    "# transformed sentiment data\n",
    "sentiment_data = lb.fit_transform(imdb_data[\"sentiment\"])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 1)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Spliting the sentiment data\n",
    "train_sentiments = sentiment_data[:40000]\n",
    "test_sentiments = sentiment_data[40000:]\n",
    "print(train_sentiments.shape)\n",
    "print(test_sentiments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Model\n",
    "\n",
    "In this section we will look at training a Bayes model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsdevnull/Documents/githubProjects/sentiment-analysis-imdb/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsdevnull/Documents/githubProjects/sentiment-analysis-imdb/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "mnb = MultinomialNB()\n",
    "# fitting the svm for bag of words\n",
    "mnb_bow = mnb.fit(cv_train_reviews, train_sentiments)\n",
    "print(mnb_bow)\n",
    "# fitting the svm for tfidf features\n",
    "mnb_tfidf = mnb.fit(tv_train_reviews, train_sentiments)\n",
    "print(mnb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the model for bag of words\n",
    "mnb_bow_predict = mnb.predict(cv_test_reviews)\n",
    "print(mnb_bow_predict)\n",
    "# Predicting the model for tfidf features\n",
    "mnb_tfidf_predict = mnb.predict(tv_test_reviews)\n",
    "print(mnb_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb_bow_score : 0.8585\n",
      "mnb_tfidf_score : 0.8692\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score for bag of words\n",
    "mnb_bow_score = accuracy_score(test_sentiments, mnb_bow_predict)\n",
    "print(\"mnb_bow_score :\", mnb_bow_score)\n",
    "# Accuracy score for tfidf features\n",
    "mnb_tfidf_score = accuracy_score(test_sentiments, mnb_tfidf_predict)\n",
    "print(\"mnb_tfidf_score :\", mnb_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.84      0.88      0.86      4993\n",
      "    Negative       0.87      0.84      0.86      5007\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.87      0.87      0.87      4993\n",
      "    Negative       0.87      0.87      0.87      5007\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for bag of words\n",
    "mnb_bow_report = classification_report(\n",
    "    test_sentiments, mnb_bow_predict, target_names=[\"Positive\", \"Negative\"]\n",
    ")\n",
    "print(mnb_bow_report)\n",
    "# Classification report for tfidf features\n",
    "mnb_tfidf_report = classification_report(\n",
    "    test_sentiments, mnb_tfidf_predict, target_names=[\"Positive\", \"Negative\"]\n",
    ")\n",
    "print(mnb_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4199  808]\n",
      " [ 607 4386]]\n",
      "[[4367  640]\n",
      " [ 668 4325]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for bag of words\n",
    "cm_bow = confusion_matrix(test_sentiments, mnb_bow_predict, labels=[1, 0])\n",
    "print(cm_bow)\n",
    "# confusion matrix for tfidf features\n",
    "cm_tfidf = confusion_matrix(test_sentiments, mnb_tfidf_predict, labels=[1, 0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model\n",
    "\n",
    "This section will go over using a linear regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsdevnull/Documents/githubProjects/sentiment-analysis-imdb/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsdevnull/Documents/githubProjects/sentiment-analysis-imdb/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "lr = LogisticRegression(penalty=\"l2\", max_iter=500, C=1, random_state=42)\n",
    "# Fitting the model for Bag of words\n",
    "lr_bow = lr.fit(cv_train_reviews, train_sentiments)\n",
    "print(lr_bow)\n",
    "# Fitting the model for tfidf features\n",
    "lr_tfidf = lr.fit(tv_train_reviews, train_sentiments)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n",
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the model for bag of words\n",
    "lr_bow_predict = lr.predict(cv_test_reviews)\n",
    "print(lr_bow_predict)\n",
    "##Predicting the model for tfidf features\n",
    "lr_tfidf_predict = lr.predict(tv_test_reviews)\n",
    "print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_bow_score : 0.8238\n",
      "lr_tfidf_score : 0.8559\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score for bag of words\n",
    "lr_bow_score = accuracy_score(test_sentiments, lr_bow_predict)\n",
    "print(\"lr_bow_score :\", lr_bow_score)\n",
    "# Accuracy score for tfidf features\n",
    "lr_tfidf_score = accuracy_score(test_sentiments, lr_tfidf_predict)\n",
    "print(\"lr_tfidf_score :\", lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.81      0.84      0.83      4993\n",
      "    Negative       0.84      0.80      0.82      5007\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.87      0.83      0.85      4993\n",
      "    Negative       0.84      0.88      0.86      5007\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for bag of words\n",
    "lr_bow_report = classification_report(\n",
    "    test_sentiments, lr_bow_predict, target_names=[\"Positive\", \"Negative\"]\n",
    ")\n",
    "print(lr_bow_report)\n",
    "\n",
    "# Classification report for tfidf features\n",
    "lr_tfidf_report = classification_report(\n",
    "    test_sentiments, lr_tfidf_predict, target_names=[\"Positive\", \"Negative\"]\n",
    ")\n",
    "print(lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4023  984]\n",
      " [ 778 4215]]\n",
      "[[4390  617]\n",
      " [ 824 4169]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for bag of words\n",
    "cm_bow = confusion_matrix(test_sentiments, lr_bow_predict, labels=[1, 0])\n",
    "print(cm_bow)\n",
    "# confusion matrix for tfidf features\n",
    "cm_tfidf = confusion_matrix(test_sentiments, lr_tfidf_predict, labels=[1, 0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "We can see that we have about an 85% accuracy with this model! That is not bad, lets test some manually entered text.\n",
    "\n",
    "Reviews that will be used in this section:\n",
    "\n",
    "Breaking Bad is a radical type of television, and also a very strange kind of must-watch: a show that you dread and crave at the same time. - Positive\n",
    "\n",
    "Taut, efficient and directed with a scalpel, Breaking Bad remains a marvel. - Positive\n",
    "\n",
    "A freak with a falsetto voice running around acting stupid, come on. After watching three episodes I still cannot say exactly what the show is about and I found that I was looking forward to the commercials and the sweet release of the end credits. I don't know what they were taking at Nickelodeon when they decided to put this show on TV but I want some. Instead of airing episodes of Fred they should just send out whatever it is they are taking so we all feel good. I understand that Fred was a YouTube Star. Perhaps Fred should return to the internet and Nickelodeon should find some shows that appeal to the entire family. Nickelodeon said they were looking into why Disney beat them in the ratings; the answer is FRED. - Negative\n",
    "\n",
    "This is one of the worst shows ever to hit T.V. besides Little Miss Perfect. I could not tolerate even after 2 minutes of this garbage. This show is about moms teaching their kids how to dress up like a prostitute for pageants that are below the age of about 8! This show is supposed to be about toddlers, why do they got seven year olds in there? This title doesn't even make sense! The kids are ugly, the moms are pressuring their kids to do challenging exercises, why can't they just treat their kid as if they were a kid? I can't believe what America has come to! Seriously, this series has got to be fake! - Negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            manually_curated_reviews\n",
      "0  break bad radic type televis also veri strang ...\n",
      "1  taut effici direct scalpel break bad remain ma...\n",
      "2  freak falsetto voic run around act stupid come...\n",
      "3  thi one worst show ever hit tv besid littl mis...\n"
     ]
    }
   ],
   "source": [
    "review_list = [\n",
    "    \"Breaking Bad is a radical type of television, and also a very strange kind of must-watch: a show that you dread and crave at the same time.\",\n",
    "    \"Taut, efficient and directed with a scalpel, Breaking Bad remains a marvel.\",\n",
    "    \"A freak with a falsetto voice running around acting stupid, come on. After watching three episodes I still cannot say exactly what the show is about and I found that I was looking forward to the commercials and the sweet release of the end credits. I don't know what they were taking at Nickelodeon when they decided to put this show on TV but I want some. Instead of airing episodes of Fred they should just send out whatever it is they are taking so we all feel good. I understand that Fred was a YouTube Star. Perhaps Fred should return to the internet and Nickelodeon should find some shows that appeal to the entire family. Nickelodeon said they were looking into why Disney beat them in the ratings; the answer is FRED.\",\n",
    "    \"This is one of the worst shows ever to hit T.V. besides Little Miss Perfect. I could not tolerate even after 2 minutes of this garbage. This show is about moms teaching their kids how to dress up like a prostitute for pageants that are below the age of about 8! This show is supposed to be about toddlers, why do they got seven year olds in there? This title doesn't even make sense! The kids are ugly, the moms are pressuring their kids to do challenging exercises, why can't they just treat their kid as if they were a kid? I can't believe what America has come to! Seriously, this series has got to be fake!\",\n",
    "]\n",
    "\n",
    "manual_reviews = pd.DataFrame(review_list, columns=[\"manually_curated_reviews\"])\n",
    "\n",
    "# Text Preprocessing\n",
    "manual_reviews[\"manually_curated_reviews\"] = manual_reviews[\n",
    "    \"manually_curated_reviews\"\n",
    "].apply(clean_html)\n",
    "manual_reviews[\"manually_curated_reviews\"] = manual_reviews[\n",
    "    \"manually_curated_reviews\"\n",
    "].apply(remove_spec_char)\n",
    "manual_reviews[\"manually_curated_reviews\"] = manual_reviews[\n",
    "    \"manually_curated_reviews\"\n",
    "].str.lower()\n",
    "manual_reviews[\"manually_curated_reviews\"] = manual_reviews[\n",
    "    \"manually_curated_reviews\"\n",
    "].apply(simple_stemmer)\n",
    "manual_reviews[\"manually_curated_reviews\"] = manual_reviews[\n",
    "    \"manually_curated_reviews\"\n",
    "].apply(remove_stop_words)\n",
    "\n",
    "print(manual_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Manual Testing\n",
    "lr_bow_prediction_manual = lr_bow.predict(\n",
    "    cv.transform(manual_reviews[\"manually_curated_reviews\"])\n",
    ")\n",
    "lr_tfidf_prediction_manual = lr.predict(\n",
    "    cv.transform(manual_reviews[\"manually_curated_reviews\"])\n",
    ")\n",
    "print(lr_bow_prediction_manual)\n",
    "print(lr_tfidf_prediction_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Assessment\n",
    "\n",
    "I am surprised by this, after doing some more testing though, the reason we are getting all negative results is because the title of the show \"Breaking Bad\" is present in the review, this lets the model believe that the review itself has a negative sentiment. I tested this by removing 'Bad' from the review and it ended up being the case.\n",
    "\n",
    "One future enhancement that can be made, is checking if the name of the show is present in the review, if it is, we can remove it. This can be something done once webscrapping is implemented and I can get my own reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0]\n",
      "[0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes Model Manual Testing\n",
    "mnb_bow_prediction_testing = mnb.predict(\n",
    "    cv.transform(manual_reviews[\"manually_curated_reviews\"])\n",
    ")\n",
    "mnb_tfidf_prediction_testing = mnb.predict(\n",
    "    cv.transform(manual_reviews[\"manually_curated_reviews\"])\n",
    ")\n",
    "\n",
    "print(mnb_bow_prediction_testing)\n",
    "print(mnb_tfidf_prediction_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Model Assessment\n",
    "\n",
    "I am pleasanty surprised that this worked out better than the linear regression model. Still seemed to have failed in the first review because of the title being breaking bad, but I am not sure right now. Further evaluation will need to be made.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mn_bays_tfidf_sentiment_analysis.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exporting the models to be added to hugging face or implemented in other projects!\n",
    "import joblib\n",
    "\n",
    "joblib.dump(lr_bow, \"linear_regression_bow_sentiment_analysis.pkl\")\n",
    "joblib.dump(lr_tfidf, \"linear_regression_tfidf_sentiment_analysis.pkl\")\n",
    "joblib.dump(mnb_bow, \"mn_bayes_bow_sentiment_analysis.pkl\")\n",
    "joblib.dump(mnb_tfidf, \"mn_bays_tfidf_sentiment_analysis.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
